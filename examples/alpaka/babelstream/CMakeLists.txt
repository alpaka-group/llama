cmake_minimum_required (VERSION 3.18.3)
project(llama-alpaka-babelstream CXX)

if (NOT TARGET llama::llama)
	find_package(llama REQUIRED)
endif()
find_package(alpaka 0.9.0 REQUIRED)
if (alpaka_ACC_GPU_CUDA_ENABLE AND (CMAKE_CUDA_COMPILER_ID STREQUAL "NVIDIA") AND
    (CMAKE_CUDA_COMPILER_VERSION VERSION_GREATER_EQUAL "11.3") AND (CMAKE_CUDA_COMPILER_VERSION VERSION_LESS "11.4"))
    message(WARNING "nvcc 11.3 fails to compile babelstream. Example will not be built.")
    return()
endif ()
alpaka_add_executable(${PROJECT_NAME} main.cpp Stream.h AlpakaStream.cpp AlpakaStream.h)
target_compile_features(${PROJECT_NAME} PRIVATE cxx_std_17)
target_compile_definitions(${PROJECT_NAME} PUBLIC ALPAKA)
target_link_libraries(${PROJECT_NAME} PRIVATE llama::llama alpaka::alpaka)
